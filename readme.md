These are the codes of my project. In the evaluation folder, for each evaluation file, I have saved the corresponding results. The evaluation code and the result file have the same name. In the model folder, there are nine trained files of three models. Among them, the Classifier-Free Guidance (CFG) files are also the ones I have experimented with, but due to time constraints, I did not complete the experiments, so I did not include them in the report. The file names are the ones I saved during the experiments and have not been modified. The other files are the experimental codes I have organized. For ease of reading, I have changed the file names to correspond one-to-one with the content in the report.

Update: I applied the same patch code to a new dataset for evaluation (use same patch file and results stored in Patch_Evaluation floder) , in order to avoid the issue of overly optimistic results caused by using the same dataset for both training and pipeline checking previously. I evaluated the results of the noise diffusion model in two settings: one based on the ground truth and the other on pure generation (sampling without ground truth). All evaluation results are stored in the Evaluation_Updated folder. 