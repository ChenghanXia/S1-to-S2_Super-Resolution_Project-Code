import os
import math
import argparse
import random
import numpy as np
from typing import Optional, List, Tuple, Dict
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader



# Reproducibility

def set_seed(seed: int = 1337):
    """Set random seeds for reproducibility."""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)



# Diffusion Schedule

def cosine_beta_schedule(T: int, s: float = 0.008) -> torch.Tensor:
    """
    Cosine beta schedule from "Improved DDPM" (Nichol & Dhariwal).
    Produces betas in range [1e-5, 0.999].
    """
    steps = T + 1
    t = torch.linspace(0, T, steps, dtype=torch.float64)
    f = torch.cos(((t / T + s) / (1 + s)) * math.pi / 2) ** 2
    alpha_bar = f / f[0]
    betas = 1 - (alpha_bar[1:] / alpha_bar[:-1])
    betas = torch.clip(betas, 1e-5, 0.999)
    return betas.float()


@torch.no_grad()
def q_sample(x0, t_idx, noise, sqrt_alpha_bar, sqrt_1m_alpha_bar):
    """
    Forward diffusion step:
    x_t = sqrt(alpha_bar[t]) * x0 + sqrt(1 - alpha_bar[t]) * noise
    """
    return (
        sqrt_alpha_bar[t_idx].view(-1, 1, 1, 1) * x0 +
        sqrt_1m_alpha_bar[t_idx].view(-1, 1, 1, 1) * noise
    )



# Dataset

class S1toS2Dataset(Dataset):
    """
    Loads .npz patches generated by patch_v5.py.
    Each file must contain:
        - inputs: (C_cond, H, W)   conditioning input
        - target: (C_tgt,  H, W)   target output in [0..1]
        - mask:   (H, W)           optional, valid pixels (0=invalid)
    """
    def __init__(self, patch_dir: str, max_files: Optional[int] = None):
        self.files = [
            os.path.join(patch_dir, f)
            for f in os.listdir(patch_dir)
            if f.endswith(".npz") and os.path.isfile(os.path.join(patch_dir, f))
        ]
        self.files.sort()
        if max_files is not None:
            self.files = self.files[:max_files]

    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        data = np.load(self.files[idx])
        x_cond = np.nan_to_num(data["inputs"].astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)
        x_tgt  = np.nan_to_num(data["target"].astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)
        mask   = None
        if "mask" in data:
            mask = np.nan_to_num(data["mask"].astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)
        return torch.from_numpy(x_cond), torch.from_numpy(x_tgt), (
            torch.from_numpy(mask) if mask is not None else None
        )



# Model (U-Net)

class UNetSmall(nn.Module):
    """
    Small U-Net predicting noise.
    Input = [x_t, cond], plus a 1-channel timestep embedding map.
    """
    def __init__(self, in_ch: int, out_ch: int, base_ch: int = 64):
        super().__init__()

        def conv_block(cin, cout):
            return nn.Sequential(
                nn.Conv2d(cin, cout, 3, padding=1),
                nn.ReLU(inplace=False),
                nn.Conv2d(cout, cout, 3, padding=1),
                nn.ReLU(inplace=False),
            )

        self.inc   = nn.Sequential(nn.Conv2d(in_ch + 1, base_ch, 3, padding=1), nn.ReLU(inplace=False))
        self.down1 = nn.Sequential(conv_block(base_ch,   base_ch*2), nn.MaxPool2d(2))
        self.down2 = nn.Sequential(conv_block(base_ch*2, base_ch*4), nn.MaxPool2d(2))
        self.down3 = nn.Sequential(conv_block(base_ch*4, base_ch*8), nn.MaxPool2d(2))

        self.up3   = nn.ConvTranspose2d(base_ch*8, base_ch*4, 2, stride=2)
        self.conv3 = conv_block(base_ch*8, base_ch*4)

        self.up2   = nn.ConvTranspose2d(base_ch*4, base_ch*2, 2, stride=2)
        self.conv2 = conv_block(base_ch*4, base_ch*2)

        self.up1   = nn.ConvTranspose2d(base_ch*2, base_ch, 2, stride=2)
        self.conv1 = conv_block(base_ch*2, base_ch)

        self.outc  = nn.Conv2d(base_ch, out_ch, 1)

    def forward(self, xt_and_cond, t_idx):
        B, _, H, W = xt_and_cond.shape
        t_map = t_idx.view(B, 1, 1, 1).float().repeat(1, 1, H, W)
        x = torch.cat([xt_and_cond, t_map], dim=1)

        e1 = self.inc(x)
        e2 = self.down1(e1)
        e3 = self.down2(e2)
        e4 = self.down3(e3)

        d3 = self.up3(e4)
        d3 = torch.cat([d3, e3], dim=1)
        d3 = self.conv3(d3)

        d2 = self.up2(d3)
        d2 = torch.cat([d2, e2], dim=1)
        d2 = self.conv2(d2)

        d1 = self.up1(d2)
        d1 = torch.cat([d1, e1], dim=1)
        d1 = self.conv1(d1)

        return self.outc(d1)



# Masked Loss

def masked_mse_per_channel(pred, target, mask, band_weights=None, mask_as_weights=False):
    """
    MSE with:
      - Optional binary mask (valid pixels only)
      - Optional mask as weights (soft mask)
      - Optional per-channel weights
    """
    B, C, H, W = pred.shape

    # Build weights
    if mask is None:
        w = torch.ones((B, 1, H, W), device=pred.device, dtype=pred.dtype)
    else:
        if mask.ndim == 3:
            mask = mask.unsqueeze(1)
        mask = mask.to(pred.dtype)
        if mask_as_weights:
            mean_val = torch.clamp(mask.mean(), min=1e-6)
            w = mask / mean_val
        else:
            w = (mask > 0).to(pred.dtype)

    # Weighted MSE
    se = (pred - target) ** 2 * w
    denom = w.sum(dim=(0, 2, 3)).clamp_min(1e-6).repeat(C)
    ch_losses = se.sum(dim=(0, 2, 3)) / denom

    # Per-channel weighting
    if band_weights is not None:
        bw = band_weights.to(pred.device).view(C)
        total = (ch_losses * bw).sum() / bw.sum().clamp_min(1e-6)
    else:
        total = ch_losses.mean()

    stats = {f"ch{ci}": float(ch_losses[ci].detach().cpu()) for ci in range(C)}
    return total, stats



# EMA (Exponential Moving Average)

class EMA:
    """Track exponential moving average of model parameters."""
    def __init__(self, model, decay=0.999):
        self.decay = decay
        self.shadow = {n: p.clone() for n, p in model.state_dict().items()}

    @torch.no_grad()
    def update(self, model):
        for name, param in model.state_dict().items():
            if param.dtype.is_floating_point:
                self.shadow[name] = (1.0 - self.decay) * param + self.decay * self.shadow[name]

    def apply_shadow(self, model):
        self.backup = model.state_dict()
        model.load_state_dict(self.shadow)

    def restore(self, model):
        model.load_state_dict(self.backup)



# Training

def train_ddpm(
    patch_dir,
    model_path,
    T=1000,
    epochs=40,
    batch_size=4,
    lr=1e-5,
    base_ch=96,
    grad_clip=0.5,
    max_patches=None,
    weight_decay=1e-4,
    ema_decay=0.999,
    seed=1337,
    band_weights=None,
    mask_as_weights=False
):
    set_seed(seed)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Detect input/output channels
    # sample = np.load(os.path.join(patch_dir, os.listdir(patch_dir)[0]))
    sample_files = [f for f in os.listdir(patch_dir) if f.endswith(".npz")]
    assert len(sample_files) > 0, f"No .npz files found in {patch_dir}"
    sample = np.load(os.path.join(patch_dir, sample_files[0]))
    C_cond = sample["inputs"].shape[0]
    C_tgt = sample["target"].shape[0]
    print(f"[INFO] Channels: inputs={C_cond}, target={C_tgt}")

    # Prepare band weights
    bw_tensor = torch.tensor(band_weights, dtype=torch.float32) if band_weights else None

    # Diffusion constants
    betas = cosine_beta_schedule(T).to(device)
    alphas = 1.0 - betas
    alpha_bar = torch.cumprod(alphas, dim=0)
    sqrt_alpha_bar = torch.sqrt(alpha_bar)
    sqrt_1m_alpha_bar = torch.sqrt(1.0 - alpha_bar)

    # Data loader
    ds = S1toS2Dataset(patch_dir, max_files=max_patches)
    loader = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)

    # Model/optimizer/EMA
    model = UNetSmall(in_ch=C_cond + C_tgt, out_ch=C_tgt, base_ch=base_ch).to(device)
    opt = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
    scaler = torch.amp.GradScaler("cuda", enabled=torch.cuda.is_available())
    ema = EMA(model, decay=ema_decay)

    best_loss = float("inf")
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    last_path = model_path.replace(".pth", "_last.pth")
    best_path = model_path.replace(".pth", "_best.pth")

    for epoch in range(1, epochs + 1):
        model.train()
        running, n_batches, nan_skipped = 0.0, 0, 0
        pbar = tqdm(loader, desc=f"Epoch {epoch}/{epochs}")

        for x_cond, x0, mask in pbar:
            x_cond, x0 = x_cond.to(device), x0.to(device)
            mask_t = mask.to(device) if mask is not None else None

            if not torch.isfinite(x_cond).all() or not torch.isfinite(x0).all():
                nan_skipped += 1
                continue

            B = x0.size(0)
            t_idx = torch.randint(0, T, (B,), device=device)
            noise = torch.randn_like(x0)

            with torch.amp.autocast("cuda", enabled=torch.cuda.is_available()):
                x_t = q_sample(x0, t_idx, noise, sqrt_alpha_bar, sqrt_1m_alpha_bar)
                inp = torch.cat([x_t, x_cond], dim=1)
                pred_noise = model(inp, t_idx)

                loss, ch_stats = masked_mse_per_channel(
                    pred=pred_noise,
                    target=noise,
                    mask=mask_t,
                    band_weights=bw_tensor,
                    mask_as_weights=mask_as_weights
                )

            if not torch.isfinite(loss):
                nan_skipped += 1
                continue

            opt.zero_grad(set_to_none=True)
            scaler.scale(loss).backward()
            if grad_clip > 0:
                scaler.unscale_(opt)
                nn.utils.clip_grad_norm_(model.parameters(), grad_clip)
            scaler.step(opt)
            scaler.update()
            ema.update(model)

            running += loss.item()
            n_batches += 1
            show = {"loss": f"{loss.item():.4f}", "skipped": nan_skipped}
            show.update({k: f"{v:.4f}" for k, v in list(ch_stats.items())[:4]})
            pbar.set_postfix(**show)

        avg_loss = running / max(1, n_batches)
        print(f"→ Epoch {epoch}: avg loss = {avg_loss:.6f} (skipped {nan_skipped})")

        # Save last and best models
        ema.apply_shadow(model)
        torch.save(model.state_dict(), last_path)
        if avg_loss < best_loss:
            best_loss = avg_loss
            torch.save(model.state_dict(), best_path)
            print(f"✅ New best model saved: {best_path}")
        ema.restore(model)

    # Save final EMA model
    ema.apply_shadow(model)
    torch.save(model.state_dict(), model_path)
    print(f"✅ Final EMA model saved: {model_path}")
    ema.restore(model)



# CLI

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--patch_dir", type=str, required=True)
    ap.add_argument("--model_path", type=str, required=True)
    ap.add_argument("--T", type=int, default=1000)
    ap.add_argument("--epochs", type=int, default=40)
    ap.add_argument("--batch_size", type=int, default=4)
    ap.add_argument("--lr", type=float, default=1e-5)
    ap.add_argument("--base_ch", type=int, default=96)
    ap.add_argument("--grad_clip", type=float, default=0.5)
    ap.add_argument("--max_patches", type=int, default=None)
    ap.add_argument("--weight_decay", type=float, default=1e-4)
    ap.add_argument("--ema_decay", type=float, default=0.999)
    ap.add_argument("--seed", type=int, default=1337)
    ap.add_argument("--band_weights", nargs="*", type=float, default=None)
    ap.add_argument("--mask_as_weights", action="store_true")

    args = ap.parse_args()
    torch.set_float32_matmul_precision("high")

    train_ddpm(
        patch_dir=args.patch_dir,
        model_path=args.model_path,
        T=args.T,
        epochs=args.epochs,
        batch_size=args.batch_size,
        lr=args.lr,
        base_ch=args.base_ch,
        grad_clip=args.grad_clip,
        max_patches=args.max_patches,
        weight_decay=args.weight_decay,
        ema_decay=args.ema_decay,
        seed=args.seed,
        band_weights=args.band_weights,
        mask_as_weights=args.mask_as_weights
    )
